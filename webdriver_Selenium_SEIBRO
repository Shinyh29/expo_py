import pandas as pd
from pandas.tseries.offsets import BDay
from selenium import webdriver
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions
from selenium.webdriver.common.by import By
##from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import ElementNotVisibleException

driver = webdriver.Chrome(executable_path='C:\\chrome_drv\\chromedriver.exe')

url = "http://www.seibro.or.kr/websquare/control.jsp?w2xPath=/IPORTAL/user/company/BIP_CNTS01045V.xml&menuNo=284"
from bs4 import BeautifulSoup as btfs

import time
today = pd.datetime.today()

#### 이아래 전체를  크롤러로 만들 수도 있겠다. (단 10페이지가 넘어가면 곤란 ?)
실행횟수 = 28
t_chain = 25    #25 넘어가면 로딩길어짐 타임아웃
T = 실행횟수 * t_chain +3  ## 해가 넘어가니까 +1 ?


## t_chain __ is fixed
## n 번째 실행: T == n * t_chain
t_end =  (today-BDay(T)-pd.tseries.offsets.Day(1))
print(t_end)
t_start =  (t_end -BDay(t_chain))   #+ pd.tseries.offsets.Day(5)
print(t_start)
# .strftime('%Y%m%d')
driver.get(url)
time.sleep(4.5)


ActionChains(driver).move_to_element(
    driver.find_elements_by_class_name('w2inputCalendar_col_input')[0]).click().click().send_keys(t_start.strftime("%Y%m%d")).perform()
time.sleep(0.5)
ActionChains(driver).move_to_element(
    driver.find_elements_by_class_name('w2inputCalendar_col_input')[1]).click().click().send_keys(t_end.strftime("%Y%m%d")).perform()
## find_elements 로 다 찾아서 [0]첫번쨰것. 서치시작~ 다음것[1] 조회끗날

driver.find_element_by_xpath('//*[@id="image2"]').click()  # 조회

time.sleep(4)

dfs = pd.DataFrame()





def frame_sele(ppath):
    global dfs
    df = pd.read_html(driver.page_source)[0]
    dfs = pd.concat([dfs, df])
    print("this_page: %d" % (i-1) )
    print(df.tail())
    print("next_page: %d" % i,  ppath )
    driver.find_element_by_xpath(ppath).click()
    # ActionChains(driver).move_to_element(driver.find_element_by_class_name('w2inputCalendar_col_input')).click().click().send_keys('20190301').perform()
    # 더블클릭, 달력날짜값전달가능 한달씩이 최적

# wait until someid is clickable
#wait = WebDriverWait(driver, 10)
#element = wait.until(expected_conditions.element_to_be_clickable((By.ID, 'someid')))
last_page = len(driver.find_elements_by_class_name('w2pageList_li_label'))
#if last_page >10:
#    last_page~~~~ 이때는 또 err 가 났음
#


for i in range(2, last_page+1):
    ppath = '//*[@id="cntsPaging01_page_%d"]' % i
    time.sleep(3)
    try:
        WebDriverWait(driver, 20).until(expected_conditions.invisibility_of_element((By.CSS_SELECTOR, '#___processbar2_i')))
        print('loaded-------!')
        frame_sele(ppath)
    #except ElementNotVisibleException:
    except:
        print('-------------로딩이 20초 넘어간경우--------or 안기다려도됨-----')
        frame_sele(ppath)
        try:
            WebDriverWait(driver, 20).until(
                expected_conditions.invisibility_of_element((By.CSS_SELECTOR, '#___processbar2_i')))
            print('loaded-------!')
            frame_sele(ppath)
        #except ElementNotVisibleException:
        except:
            print('-------------로딩이 20초 넘어간경우--------or 안기다려도됨-----')
            frame_sele(ppath)
            try:
                WebDriverWait(driver, 20).until(
                    expected_conditions.invisibility_of_element((By.CSS_SELECTOR, '#___processbar2_i')))
                print('loaded-------!')
                frame_sele(ppath)
            #except ElementNotVisibleException:
            except:
                print('-------------로딩이 20초 넘어간경우--------or 안기다려도됨-----')
                print('-------------조회가능한 페이지가 더이상 없는경우 ---------------')
                frame_sele(ppath)
                break

try:
    WebDriverWait(driver, 20).until(
        expected_conditions.invisibility_of_element((By.CSS_SELECTOR, '#___processbar2_i')))
    print('loaded-------!')
    df = pd.read_html(driver.page_source)[0]
    dfs = pd.concat([dfs, df])
    print("this_page: %d" % (i ))
    print(df.tail())

    # 마지막 page
except:
    print('-------------로딩이 20초 넘어간경우--------or 안기다려도됨-----')
    print('-------------조회가능한 페이지가 더이상 없는경우 ---------------')
    df = pd.read_html(driver.page_source)[0]
    dfs = pd.concat([dfs, df])
    print("last_page: %d" % (i ))
    print(df.tail())

    # 마지막 page


print(dfs)

print(type(dfs))
print(t_end)
print(t_start)
print('실행횟수_from today : ',  실행횟수)
driver.quit()
##dfs.to_excel('C:\\Users\\exp19103\\shinyh\\python\\' + t_start+'부터한달.xlsx')



#writer = pd.ExcelWriter('C:\\seibros.xlsx', engine = 'xlsxwriter')
dfs.to_excel('C:\\Users\\exp19103\\shinyh\\python\\' + t_start.strftime("%Y%m%d")+"_25.xlsx")
#writer.save()

